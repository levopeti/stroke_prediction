{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "https://www.kaggle.com/code/purplejester/pytorch-deep-time-series-classification"
   ],
   "metadata": {
    "id": "8PRi5y0YAgCC"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import time\n",
    "\n",
    "from glob import glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.nn import Module\n",
    "from torch.nn.functional import sigmoid, one_hot\n",
    "from torch.optim import Optimizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "from measurement_utils.measure_db import MeasureDB"
   ],
   "metadata": {
    "id": "6jGaGM39ZDDB",
    "ExecuteTime": {
     "end_time": "2023-09-29T15:46:25.156050184Z",
     "start_time": "2023-09-29T15:46:23.400575934Z"
    }
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def calculate_diff(x_y_z, meas_type_acc) -> np.ndarray:\n",
    "    if meas_type_acc:\n",
    "        x_diff, y_diff, z_diff = [np.diff(m) for m in x_y_z]\n",
    "    else:\n",
    "        x_diff, y_diff, z_diff = x_y_z\n",
    "\n",
    "    result = np.abs(x_diff) + np.abs(y_diff) + np.abs(z_diff)\n",
    "    assert len(result) > 0\n",
    "    return result\n",
    "\n",
    "def get_diff(x_y_z, meas_type_acc, length=None, start_idx=None):\n",
    "    cut_x_y_z = list()\n",
    "    for array in x_y_z:\n",
    "      if length is not None:\n",
    "          assert length < len(array)\n",
    "\n",
    "          start_idx = start_idx if start_idx is not None else random.randint(0, len(array) - (length + 1))\n",
    "          if start_idx > len(array) - (length + 1):\n",
    "              raise ValueError(\"start_idx is too large\")\n",
    "\n",
    "          cut_x_y_z.append(array[start_idx:start_idx + length])\n",
    "      else:\n",
    "          cut_x_y_z = x_y_z\n",
    "\n",
    "    result = calculate_diff(cut_x_y_z, meas_type_acc)\n",
    "\n",
    "    assert len(result) > 0\n",
    "    return result\n",
    "\n",
    "def get_limb_diff_mean(left_x_y_z, right_x_y_z, meas_type_acc, length=None, start_idx=None):\n",
    "    left_diff = get_diff(left_x_y_z, meas_type_acc, length, start_idx)\n",
    "    right_diff = get_diff(right_x_y_z, meas_type_acc, length, start_idx)\n",
    "    result = np.abs(left_diff.mean() - right_diff.mean())\n",
    "    return result\n",
    "\n",
    "def get_limb_ratio_mean(left_x_y_z, right_x_y_z, meas_type_acc,\n",
    "                        class_value_left, class_value_right,\n",
    "                        length=None, start_idx=None, mean_first=True):\n",
    "    left_diff = get_diff(left_x_y_z, meas_type_acc, length, start_idx)\n",
    "    right_diff = get_diff(right_x_y_z, meas_type_acc, length, start_idx)\n",
    "\n",
    "    if mean_first:\n",
    "        if class_value_left > class_value_right:\n",
    "            result = left_diff.sum() / right_diff.sum()\n",
    "        else:\n",
    "            result = right_diff.sum() / left_diff.sum()\n",
    "    else:\n",
    "        left_diff = left_diff + 0.1\n",
    "        right_diff = right_diff + 0.1\n",
    "        if class_value_left > class_value_right:\n",
    "            result = np.mean(left_diff / right_diff)\n",
    "        else:\n",
    "            result = np.mean(right_diff / left_diff)\n",
    "    return result\n",
    "\n",
    "def get_input_from_df(meas_df: pd.DataFrame, length: int, class_value_dict: dict) -> np.ndarray:\n",
    "    keys_in_order = ((\"arm\", \"acc\"),\n",
    "                     (\"leg\", \"acc\"),\n",
    "                     (\"arm\", \"gyr\"),\n",
    "                     (\"leg\", \"gyr\"))\n",
    "\n",
    "    result = list()\n",
    "    for key in keys_in_order:\n",
    "        class_value_left = class_value_dict[(\"left\", key[0])]\n",
    "        class_value_right = class_value_dict[(\"right\", key[0])]\n",
    "\n",
    "        left_x_y_z = [meas_df[str(((\"left\", key[0], key[1], \"x\")))].values,\n",
    "                      meas_df[str(((\"left\", key[0], key[1], \"y\")))].values,\n",
    "                      meas_df[str(((\"left\", key[0], key[1], \"z\")))].values]\n",
    "\n",
    "        right_x_y_z = [meas_df[str(((\"right\", key[0], key[1], \"x\")))].values,\n",
    "                       meas_df[str(((\"right\", key[0], key[1], \"y\")))].values,\n",
    "                       meas_df[str(((\"right\", key[0], key[1], \"z\")))].values]\n",
    "        meas_type_acc = key[1] == \"acc\"\n",
    "        diff_mean = get_limb_diff_mean(left_x_y_z, right_x_y_z, meas_type_acc, length, start_idx=None)\n",
    "        ratio_mean_first = get_limb_ratio_mean(left_x_y_z, right_x_y_z, meas_type_acc, class_value_left, class_value_right, length, mean_first=True, start_idx=None)\n",
    "        ratio_mean = get_limb_ratio_mean(left_x_y_z, right_x_y_z, meas_type_acc, class_value_left, class_value_right, length, mean_first=False, start_idx=None)\n",
    "        result.extend([diff_mean, ratio_mean, ratio_mean_first])\n",
    "\n",
    "    return np.expand_dims(np.array(result), axis=0)"
   ],
   "metadata": {
    "id": "FAduAQpUxb4i",
    "ExecuteTime": {
     "end_time": "2023-09-29T15:46:25.171881869Z",
     "start_time": "2023-09-29T15:46:25.167290636Z"
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class ClearMeasurements(object):\n",
    "    def __init__(self, folder_path: str, clear_json_path: str, cache_size: int = 1) -> None:\n",
    "        assert cache_size > 0, \"cache_size must be positive integer\"\n",
    "        self.cache_size = cache_size\n",
    "        self.id_path_dict = dict()\n",
    "        self.cache_dict = dict()\n",
    "\n",
    "        self.read_csv_path(folder_path)\n",
    "        self.read_clear_json(clear_json_path)\n",
    "\n",
    "    def get_meas_id_list(self, data_type: str) -> list:\n",
    "        return sorted(self.clear_ids_dict[data_type])\n",
    "\n",
    "    def read_clear_json(self, clear_json_path: str) -> None:\n",
    "        with open(clear_json_path, \"r\") as read_file:\n",
    "            self.clear_ids_dict = json.load(read_file)\n",
    "\n",
    "        all_meas_ids = set(self.id_path_dict.keys())\n",
    "        for meas_id in self.clear_ids_dict[\"train\"]:\n",
    "            assert meas_id in all_meas_ids\n",
    "\n",
    "        for meas_id in self.clear_ids_dict[\"test\"]:\n",
    "            assert meas_id in all_meas_ids\n",
    "\n",
    "    def read_csv_path(self, folder_path: str) -> None:\n",
    "        print(\"read_csv_path\")\n",
    "        for csv_path in sorted(glob(os.path.join(folder_path, \"*.csv\"))):\n",
    "            file_name = os.path.basename(csv_path)\n",
    "            meas_id = file_name.split(\"-\")[0]\n",
    "            self.id_path_dict[int(meas_id)] = csv_path\n",
    "        print(\"done\")\n",
    "\n",
    "    def drop_random_from_cache_dict(self):\n",
    "        self.cache_dict.pop(random.choice(list(self.cache_dict.keys())))\n",
    "\n",
    "    def get_measurement(self, meas_id: int) -> pd.DataFrame:\n",
    "        if meas_id in self.cache_dict:\n",
    "            #print(\"use cache\")\n",
    "            df = self.cache_dict[meas_id]\n",
    "        else:\n",
    "            print(\"read new\")\n",
    "            if len(self.cache_dict) == self.cache_size:\n",
    "                print(\"drop from cache\")\n",
    "                self.drop_random_from_cache_dict()\n",
    "\n",
    "            csv_path = self.id_path_dict[meas_id]\n",
    "            df = pd.read_csv(csv_path)\n",
    "            self.cache_dict[meas_id] = df\n",
    "            assert len(self.cache_dict) <= self.cache_size, (len(self.cache_dict), self.cache_size)\n",
    "        return df"
   ],
   "metadata": {
    "id": "V3Q3l4TklsG6",
    "ExecuteTime": {
     "end_time": "2023-09-29T15:49:16.159014498Z",
     "start_time": "2023-09-29T15:49:16.114427622Z"
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "QAv3XHBmYrIc",
    "ExecuteTime": {
     "end_time": "2023-09-29T15:49:17.576334619Z",
     "start_time": "2023-09-29T15:49:17.573051030Z"
    }
   },
   "outputs": [],
   "source": [
    "class ClearDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 data_type: str, # train or test\n",
    "                 clear_measurements: ClearMeasurements,\n",
    "                 measDB: MeasureDB,\n",
    "                 length: int,\n",
    "                 sample_per_meas: int) -> None:\n",
    "        self.meas_id_list = clear_measurements.get_meas_id_list(data_type)\n",
    "        self.clear_measurements = clear_measurements\n",
    "        self.measDB = measDB\n",
    "        self.sample_per_meas = sample_per_meas\n",
    "        self.length = length\n",
    "\n",
    "        self.meas_idx = 0\n",
    "        self.to_tensor = ToTensor()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.meas_id_list) * self.sample_per_meas\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #print(idx)\n",
    "        meas_idx = idx // self.sample_per_meas\n",
    "        meas_id = self.meas_id_list[meas_idx]\n",
    "        #start = time.time()\n",
    "        #print(111)\n",
    "        meas_df = self.clear_measurements.get_measurement(meas_id)\n",
    "        #print(\"get meas {} took {:.2}s\".format(meas_id, time.time() - start))\n",
    "\n",
    "        class_value_dict = self.measDB.get_class_value_dict(meas_id=meas_id)\n",
    "        #start = time.time()\n",
    "        input_array = get_input_from_df(meas_df, self.length, class_value_dict)\n",
    "        #print(\"get input_array for {} took {:.2}s\".format(meas_id, time.time() - start))\n",
    "        input_tensor = torch.from_numpy(input_array).float()\n",
    "\n",
    "        label = min(class_value_dict.values())\n",
    "        return input_tensor, label"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def validation_step(model: Module,\n",
    "                    criterion: Module,\n",
    "                    valid_loader: DataLoader):\n",
    "\n",
    "    print(\"validation_step\")\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        loss = list()\n",
    "\n",
    "        total = 0\n",
    "        tqdm_dict = dict()\n",
    "\n",
    "        for batch_idx, (x, y) in enumerate(valid_loader):\n",
    "            total += y.size(0)\n",
    "\n",
    "            model_out = torch.squeeze(model(x.float()))\n",
    "            print(model_out.shape, y.shape)\n",
    "            loss.append(criterion(model_out, y).item())\n",
    "\n",
    "            _, predicted = model_out.max(1)\n",
    "            correct += predicted.eq(y).sum().item()\n",
    "            acc = correct / total\n",
    "\n",
    "        print(\"loss: {:.2f}, acc: {:.1f}%\".format(sum(loss) / len(loss), acc * 100))\n",
    "\n",
    "class TrainLoop(object):\n",
    "    def __init__(self,\n",
    "                 model: Module,\n",
    "                 optimizer: Optimizer,\n",
    "                 criterion: Module,\n",
    "                 train_loader: DataLoader,\n",
    "                 valid_loader: DataLoader,\n",
    "                 num_epoch: int):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.train_loader = train_loader\n",
    "        self.valid_loader = valid_loader\n",
    "        self.num_epoch = num_epoch\n",
    "\n",
    "    def run_loop(self):\n",
    "        for epoch in range(self.num_epoch):\n",
    "            print(\"\\nepoch: {}\".format(epoch))\n",
    "            self.model.train()\n",
    "\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            #tq = tqdm(total=(len(self.train_loader)))\n",
    "            #tq.set_description('ep {}'.format(epoch))\n",
    "            for batch_idx, (x, y) in enumerate(self.train_loader):\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                model_out = torch.squeeze(self.model(x.float()))\n",
    "\n",
    "                print(model_out.shape, y.shape)\n",
    "                loss = self.criterion(model_out, y)  # index of the max log-probability\n",
    "                loss.backward()\n",
    "\n",
    "                self.optimizer.step()\n",
    "\n",
    "                total += y.size(0)\n",
    "\n",
    "                _, predicted = model_out.max(1)\n",
    "                correct += predicted.eq(y).sum().item()\n",
    "\n",
    "                acc = correct / total\n",
    "\n",
    "                #tq.update(1)\n",
    "                #tq.set_postfix(loss='{:.2f}'.format(loss.item()),\n",
    "                #               acc='{:.1f}%'.format(acc * 100))\n",
    "                print(\"{:.2f}%, loss: {:.2f}, acc: {:.1f}%\".format(batch_idx/len(self.train_loader), loss.item(), acc * 100))\n",
    "\n",
    "            validation_step(self.model, self.criterion, self.valid_loader)\n"
   ],
   "metadata": {
    "id": "GzjD0fHf_gQ3",
    "ExecuteTime": {
     "end_time": "2023-09-29T16:18:35.313573367Z",
     "start_time": "2023-09-29T16:18:35.288437224Z"
    }
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "db_path = \"./data/WUS-v4measure202307311.accdb\"\n",
    "ucanaccess_path = \"./ucanaccess/\"\n",
    "folder_path = \"./data/clear_data/\"\n",
    "clear_json_path = \"./data/clear_train_test_ids.json\"\n",
    "\n",
    "length = int(1.5 * 60 * 60 * 25)  # 1.5 hours, 25 Hz\n",
    "sample_per_meas = 1\n",
    "\n",
    "measDB = MeasureDB(db_path, ucanaccess_path)\n",
    "clear_measurements = ClearMeasurements(folder_path, clear_json_path)\n",
    "\n",
    "train_dataset = ClearDataset(\"train\", clear_measurements, measDB, length, sample_per_meas)\n",
    "test_dataset = ClearDataset(\"test\", clear_measurements, measDB, length, sample_per_meas)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=3, shuffle=False, num_workers=1)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=3, shuffle=False, num_workers=1)"
   ],
   "metadata": {
    "id": "xvmwB3DSYwTq",
    "ExecuteTime": {
     "end_time": "2023-09-29T16:18:36.341264314Z",
     "start_time": "2023-09-29T16:18:35.872440825Z"
    }
   },
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read_csv_path\n",
      "done\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "inpit_size = 12\n",
    "layer_sizes = [512, 128]\n",
    "output_size = 6\n",
    "\n",
    "lr = 0.001\n",
    "wd = 0\n",
    "\n",
    "num_epoch = 10\n",
    "\n",
    "model = nn.Sequential(\n",
    "        nn.Linear(12, layer_sizes[0]),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(layer_sizes[0], layer_sizes[1]),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(layer_sizes[1], output_size)\n",
    ")\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr=lr,\n",
    "                             weight_decay=wd,\n",
    "                             amsgrad=True)\n",
    "model = model.float()\n",
    "train_loop = TrainLoop(model,\n",
    "                       optimizer,\n",
    "                       criterion,\n",
    "                       train_dataloader,\n",
    "                       test_dataloader,\n",
    "                       num_epoch)"
   ],
   "metadata": {
    "id": "_OgCiYTsKv2C",
    "ExecuteTime": {
     "end_time": "2023-09-29T16:18:36.501529927Z",
     "start_time": "2023-09-29T16:18:36.493620484Z"
    }
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_loop.run_loop()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7DUhB3l1L6WB",
    "outputId": "3fc1bd50-1c73-49fd-9aef-c48415685f2a",
    "ExecuteTime": {
     "end_time": "2023-09-29T16:35:00.956548176Z",
     "start_time": "2023-09-29T16:18:37.571622556Z"
    }
   },
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch: 0\n",
      "read new\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.00%, loss: 1.86, acc: 0.0%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.08%, loss: 1.39, acc: 33.3%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.17%, loss: 3.51, acc: 22.2%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.25%, loss: 3.00, acc: 25.0%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.33%, loss: 3.03, acc: 20.0%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.42%, loss: 2.87, acc: 22.2%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.50%, loss: 2.45, acc: 19.0%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.58%, loss: 2.11, acc: 16.7%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.67%, loss: 4.16, acc: 14.8%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.75%, loss: 2.57, acc: 13.3%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.83%, loss: 1.97, acc: 12.1%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.92%, loss: 1.86, acc: 11.1%\n",
      "validation_step\n",
      "read new\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([2, 6]) torch.Size([2])\n",
      "loss: 1.96, acc: 20.0%\n",
      "\n",
      "epoch: 1\n",
      "read new\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.00%, loss: 2.16, acc: 33.3%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.08%, loss: 2.43, acc: 16.7%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.17%, loss: 4.04, acc: 11.1%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.25%, loss: 2.14, acc: 8.3%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.33%, loss: 1.65, acc: 13.3%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.42%, loss: 1.76, acc: 16.7%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.50%, loss: 2.12, acc: 14.3%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.58%, loss: 1.86, acc: 12.5%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.67%, loss: 1.62, acc: 11.1%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.75%, loss: 1.62, acc: 10.0%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.83%, loss: 1.75, acc: 9.1%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.92%, loss: 1.87, acc: 8.3%\n",
      "validation_step\n",
      "read new\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([2, 6]) torch.Size([2])\n",
      "loss: 2.26, acc: 20.0%\n",
      "\n",
      "epoch: 2\n",
      "read new\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.00%, loss: 1.94, acc: 66.7%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.08%, loss: 2.00, acc: 50.0%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.17%, loss: 1.80, acc: 44.4%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.25%, loss: 1.56, acc: 50.0%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.33%, loss: 2.06, acc: 40.0%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.42%, loss: 1.18, acc: 44.4%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.50%, loss: 2.13, acc: 38.1%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.58%, loss: 1.88, acc: 33.3%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.67%, loss: 2.07, acc: 33.3%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.75%, loss: 1.59, acc: 36.7%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.83%, loss: 1.77, acc: 33.3%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.92%, loss: 1.70, acc: 33.3%\n",
      "validation_step\n",
      "read new\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([2, 6]) torch.Size([2])\n",
      "loss: 1.41, acc: 40.0%\n",
      "\n",
      "epoch: 3\n",
      "read new\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.00%, loss: 1.49, acc: 33.3%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.08%, loss: 2.09, acc: 50.0%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.17%, loss: 1.26, acc: 44.4%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.25%, loss: 1.82, acc: 41.7%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.33%, loss: 1.39, acc: 40.0%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.42%, loss: 1.49, acc: 38.9%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.50%, loss: 2.02, acc: 33.3%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.58%, loss: 1.82, acc: 29.2%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.67%, loss: 1.71, acc: 25.9%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.75%, loss: 1.75, acc: 26.7%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.83%, loss: 1.84, acc: 24.2%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.92%, loss: 1.78, acc: 22.2%\n",
      "validation_step\n",
      "read new\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([2, 6]) torch.Size([2])\n",
      "loss: 1.65, acc: 20.0%\n",
      "\n",
      "epoch: 4\n",
      "read new\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.00%, loss: 1.57, acc: 33.3%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.08%, loss: 2.01, acc: 16.7%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.17%, loss: 2.48, acc: 33.3%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.25%, loss: 1.45, acc: 41.7%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.33%, loss: 2.81, acc: 33.3%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.42%, loss: 1.52, acc: 33.3%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.50%, loss: 1.98, acc: 28.6%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.58%, loss: 1.86, acc: 25.0%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.67%, loss: 1.96, acc: 22.2%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.75%, loss: 1.48, acc: 23.3%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.83%, loss: 1.87, acc: 21.2%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.92%, loss: 1.59, acc: 25.0%\n",
      "validation_step\n",
      "read new\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([2, 6]) torch.Size([2])\n",
      "loss: 1.48, acc: 40.0%\n",
      "\n",
      "epoch: 5\n",
      "read new\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.00%, loss: 1.39, acc: 66.7%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.08%, loss: 1.56, acc: 50.0%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.17%, loss: 1.66, acc: 33.3%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.25%, loss: 2.07, acc: 33.3%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.33%, loss: 1.99, acc: 26.7%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.42%, loss: 2.52, acc: 22.2%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.50%, loss: 1.22, acc: 23.8%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.58%, loss: 1.61, acc: 20.8%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.67%, loss: 2.79, acc: 22.2%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.75%, loss: 1.70, acc: 23.3%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.83%, loss: 1.74, acc: 21.2%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.92%, loss: 1.90, acc: 19.4%\n",
      "validation_step\n",
      "read new\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([2, 6]) torch.Size([2])\n",
      "loss: 1.65, acc: 40.0%\n",
      "\n",
      "epoch: 6\n",
      "read new\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.00%, loss: 1.68, acc: 33.3%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.08%, loss: 1.62, acc: 50.0%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.17%, loss: 2.21, acc: 33.3%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.25%, loss: 1.44, acc: 33.3%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.33%, loss: 1.16, acc: 33.3%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.42%, loss: 1.31, acc: 33.3%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.50%, loss: 1.51, acc: 33.3%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.58%, loss: 1.82, acc: 29.2%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.67%, loss: 2.46, acc: 25.9%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.75%, loss: 1.83, acc: 26.7%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.83%, loss: 1.99, acc: 24.2%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.92%, loss: 2.02, acc: 22.2%\n",
      "validation_step\n",
      "read new\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([2, 6]) torch.Size([2])\n",
      "loss: 1.90, acc: 20.0%\n",
      "\n",
      "epoch: 7\n",
      "read new\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.00%, loss: 1.81, acc: 0.0%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.08%, loss: 1.69, acc: 33.3%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.17%, loss: 1.91, acc: 22.2%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.25%, loss: 1.54, acc: 25.0%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.33%, loss: 1.45, acc: 26.7%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.42%, loss: 1.57, acc: 33.3%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.50%, loss: 1.56, acc: 28.6%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.58%, loss: 1.85, acc: 29.2%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.67%, loss: 0.75, acc: 33.3%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.75%, loss: 1.68, acc: 33.3%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.83%, loss: 1.59, acc: 36.4%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.92%, loss: 1.83, acc: 33.3%\n",
      "validation_step\n",
      "read new\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([2, 6]) torch.Size([2])\n",
      "loss: 1.47, acc: 60.0%\n",
      "\n",
      "epoch: 8\n",
      "read new\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.00%, loss: 1.45, acc: 33.3%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.08%, loss: 1.71, acc: 16.7%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.17%, loss: 2.42, acc: 11.1%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.25%, loss: 1.40, acc: 16.7%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.33%, loss: 1.52, acc: 13.3%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.42%, loss: 1.20, acc: 16.7%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.50%, loss: 1.36, acc: 19.0%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.58%, loss: 1.72, acc: 16.7%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.67%, loss: 1.94, acc: 14.8%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.75%, loss: 1.86, acc: 16.7%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.83%, loss: 1.84, acc: 18.2%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.92%, loss: 2.77, acc: 16.7%\n",
      "validation_step\n",
      "read new\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([2, 6]) torch.Size([2])\n",
      "loss: 1.52, acc: 20.0%\n",
      "\n",
      "epoch: 9\n",
      "read new\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.00%, loss: 1.78, acc: 0.0%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.08%, loss: 1.87, acc: 0.0%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.17%, loss: 1.39, acc: 11.1%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.25%, loss: 1.70, acc: 16.7%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.33%, loss: 1.22, acc: 20.0%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.42%, loss: 1.21, acc: 22.2%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.50%, loss: 0.96, acc: 28.6%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.58%, loss: 1.97, acc: 25.0%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.67%, loss: 1.71, acc: 22.2%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.75%, loss: 1.74, acc: 23.3%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.83%, loss: 1.65, acc: 24.2%\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "0.92%, loss: 1.78, acc: 25.0%\n",
      "validation_step\n",
      "read new\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([3, 6]) torch.Size([3])\n",
      "read new\n",
      "drop from cache\n",
      "torch.Size([2, 6]) torch.Size([2])\n",
      "loss: 1.45, acc: 60.0%\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\n"
   ],
   "metadata": {
    "id": "dqBQJ2oNL8d_"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
